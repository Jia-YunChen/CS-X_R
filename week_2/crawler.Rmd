---
title: "Cramler"
author: "JiaYun"
date: "2018年9月26日"
output: html_document
---
# Crawler

## 目標網站

某個討論小說歌詞的個人部落格http://jy29811354.pixnet.net/blog

---

## 爬蟲過程

- 匯入所需的Packages : 

```{package_import, echo=TRUE, eval=FALSE}
library(rvest)
```

- 設定目標網站 : 

```{set_url, echo=TRUE, eval=FALSE}
URL <- ("http://jy29811354.pixnet.net/blog")
```

```{set_title_name, echo=TRUE, eval=FALSE}
title <- c(1: 9)
```

- 擷取所有網站中標題 :

```{for_loop, echo=TRUE, eval=FALSE}
for (x in c(1: 8)) {
  title.temp <- read_html(URL[x])
  
  title.temp <- html_nodes(title.temp, ".title")
  
  title.temp <- html_text(title.temp)
  
  title.temp <- title.temp[c(1: 9)]
  
  title <- rbind(title, title.temp)
  
}
```

- 儲存擷取出的資料

```{dataframe, echo=TRUE, eval=FALSE}
title <- as.data.frame(title)
rownames(title) <- title.name
save(title, file='website_title.RData')
```
---
## 爬蟲感想

第一次接觸到網路爬蟲相關的做法，花了很多的時間在搞清楚他的來龍去脈，雖然程式碼並不複雜，但我還是必須一步一步去看才搞懂每個步驟背後的意義，也要謝謝有同學、助教可以給我請教!雖然我找的資料很單純很簡單，但還是很開心是自己做出來!!!

